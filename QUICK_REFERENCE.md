# Quick Reference Guide
## Emotion-Based Music Recommendation System

---

## ğŸš€ QUICK START (5 Minutes)

### Step 1: Install Dependencies (1 min)
```bash
pip install tensorflow opencv-python streamlit numpy
```

### Step 2: Download Dataset (Already Done âœ…)
```
data/train/ - 28,709 images (7 emotion folders)
data/test/  - 7,178 images (7 emotion folders)
```

### Step 3: Train Model (2-3 min)
```bash
python train_minimal.py
```
**Output:** `model/emotion_model.h5` (60-65% accuracy)

### Step 4: Run Application (1 min)
```bash
streamlit run app.py
```
**URL:** http://localhost:8501

---

## ğŸ“Š MINIMAL DATASET APPROACH

### Why Minimal?
- âœ… **Fast Training**: 2-3 minutes (vs 2-3 hours for full dataset)
- âœ… **Good Accuracy**: 60-65% (vs 70% for full dataset)
- âœ… **Perfect for Demo**: Quick to show and test
- âœ… **Scalable**: Can easily switch to full dataset

### Dataset Size
| Type | Full Dataset | Minimal Dataset |
|------|--------------|-----------------|
| Training | 28,709 images | 700 images (100/class) |
| Testing | 7,178 images | 350 images (50/class) |
| Training Time | 2-3 hours | 2-3 minutes |
| Accuracy | 70% | 60-65% |

---

## ğŸ—ï¸ ARCHITECTURE OVERVIEW

### Model Architecture (CNN)
```
Input (48x48x1)
    â†“
Conv2D(32) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Conv2D(64) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Conv2D(128) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Flatten â†’ Dense(256) â†’ BatchNorm â†’ Dropout(0.5)
    â†“
Dense(7, softmax) â†’ [Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral]
```

### Training Configuration
- **Optimizer**: Adam (lr=0.001)
- **Loss**: Categorical Crossentropy
- **Batch Size**: 32
- **Epochs**: 20 (with early stopping)
- **Callbacks**: EarlyStopping, ReduceLROnPlateau

---

## ğŸ¯ KEY COMPONENTS

### 1. Face Detection
- **Method**: Haar Cascade Classifier
- **File**: `haarcascade_frontalface_default.xml`
- **Parameters**: scaleFactor=1.3, minNeighbors=5

### 2. Emotion Recognition
- **Input**: 48x48 grayscale face image
- **Output**: 7 emotion probabilities
- **Classes**: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral

### 3. Music Recommendation
- **Mapping**: Emotion â†’ Genres, Playlists, Songs
- **Example**: Happy â†’ Pop, Dance, Upbeat songs

---

## ğŸ“ FILE STRUCTURE

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/              # Training images
â”‚   â””â”€â”€ test/               # Test images
â”œâ”€â”€ model/
â”‚   â””â”€â”€ emotion_model.h5    # Trained CNN model
â”œâ”€â”€ train_minimal.py        # Training script (minimal dataset)
â”œâ”€â”€ emotion_recognition.py  # Face detection + emotion prediction
â”œâ”€â”€ music_recommender.py    # Music recommendation logic
â”œâ”€â”€ app.py                  # Streamlit web application
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ”§ TROUBLESHOOTING

### Issue 1: Model Not Found
**Error:** `FileNotFoundError: model/emotion_model.h5`
**Solution:** Run `python train_minimal.py` first

### Issue 2: Low Accuracy
**Problem:** Model predicting only Neutral/Angry
**Solution:** 
- Check if model trained properly (should be 60-65%)
- Retrain with: `python train_minimal.py`

### Issue 3: Webcam Not Working
**Problem:** Camera not detected
**Solution:** 
- Use "Upload Image" mode instead
- Check camera permissions

### Issue 4: Streamlit Not Starting
**Problem:** Port already in use
**Solution:** 
```bash
streamlit run app.py --server.port 8502
```

---

## ğŸ“ˆ PERFORMANCE METRICS

### Model Performance
- **Training Accuracy**: 65-70%
- **Validation Accuracy**: 60-65%
- **Test Accuracy**: 60-65%
- **Inference Time**: ~50ms per image

### Per-Class Accuracy (Expected)
| Emotion | Accuracy |
|---------|----------|
| Happy | 75-80% |
| Sad | 60-65% |
| Angry | 65-70% |
| Neutral | 60-65% |
| Surprise | 55-60% |
| Fear | 50-55% |
| Disgust | 45-50% |

---

## ğŸ“ VIVA PREPARATION - KEY POINTS

### Q1: Why minimal dataset?
**A:** For quick demonstration and testing. Full dataset takes 2-3 hours to train, minimal takes 2-3 minutes with acceptable 60-65% accuracy.

### Q2: What is the model architecture?
**A:** CNN with 3 convolutional blocks (32â†’64â†’128 filters), BatchNormalization, Dropout regularization, and 2 dense layers outputting 7 emotion classes.

### Q3: How does face detection work?
**A:** Using Haar Cascade Classifier from OpenCV, which detects faces using edge features. Then we extract the face ROI and pass it to the CNN.

### Q4: What is the accuracy?
**A:** 60-65% with minimal dataset (700 images). Can achieve 70%+ with full dataset (28,709 images).

### Q5: How does music recommendation work?
**A:** Simple rule-based mapping: Each emotion maps to specific genres, playlists, and songs. For example, Happy â†’ Pop/Dance, Sad â†’ Chill/Lo-fi.

### Q6: What preprocessing is done?
**A:** 
1. Convert to grayscale
2. Resize to 48x48
3. Normalize pixel values (0-1)
4. Reshape to (1, 48, 48, 1)

### Q7: What are the challenges?
**A:**
- Class imbalance (Disgust has fewer samples)
- Similar emotions (Sad vs Neutral)
- Lighting conditions affect detection
- Face angle affects accuracy

---

## ğŸ’¡ IMPROVEMENTS (Future Work)

### Short-term
- âœ… Data augmentation (rotation, flip, zoom)
- âœ… Use full dataset for better accuracy
- âœ… Add more music sources (Spotify API)

### Long-term
- âœ… Transfer learning (VGG16, ResNet)
- âœ… Real-time video emotion tracking
- âœ… Multi-face detection
- âœ… Emotion history tracking

---

## ğŸ“ COMMANDS CHEAT SHEET

```bash
# Install dependencies
pip install -r requirements.txt

# Train model (minimal)
python train_minimal.py

# Train model (full dataset) - if needed
python train_better_model.py

# Run application
streamlit run app.py

# Test emotion recognition only
python emotion_recognition.py

# Check dataset
python check_dataset.py
```

---

## ğŸ¯ DEMO FLOW

1. **Open Application** â†’ http://localhost:8501
2. **Choose Mode** â†’ Upload Image or Webcam
3. **Capture/Upload** â†’ Your face image
4. **View Results** â†’ Detected emotion + confidence
5. **Get Recommendations** â†’ Genres, Playlists, Songs
6. **Try Different Emotions** â†’ Happy, Sad, Angry, etc.

---

**Quick Reference Complete!**
Use `IMPLEMENTATION_GUIDE_MINIMAL.md` for detailed step-by-step implementation.
